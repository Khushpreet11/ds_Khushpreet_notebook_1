{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIHxasD6c_on",
        "outputId": "460917b1-e4e6-47ca-8b01-a1d11049a653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.12/dist-packages (4.4.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.4)\n",
            "‚úÖ Created root directory: ds_Khushpreet and subdirectories.\n",
            "‚úÖ Files loaded successfully!\n",
            "\n",
            "Trades shape: (211224, 16)\n",
            "Sentiment shape: (2644, 4)\n",
            "‚úÖ Aggregated data saved to ds_Khushpreet/csv_files\n",
            "\n",
            "Merged dataset preview:\n",
            "         Date    avg_pnl  total_volume  total_trades  avg_leverage  \\\n",
            "0  2023-03-28   0.000000             0             3           0.0   \n",
            "1  2023-11-14   0.148807             0          1045           0.0   \n",
            "2  2024-03-09  25.418772             0          6962           0.0   \n",
            "3  2024-07-03  22.229713             0          7141           0.0   \n",
            "4  2024-10-27  90.504272             0         35241           0.0   \n",
            "\n",
            "      pnl_risk  avg_sentiment classification  \n",
            "0     0.000000           59.0          Greed  \n",
            "1   105.092113           69.0          Greed  \n",
            "2   306.166937           84.0  Extreme Greed  \n",
            "3   633.704815           50.0        Neutral  \n",
            "4  1165.052548           74.0          Greed  \n",
            "\n",
            "üìà Correlation Matrix (Sentiment vs Key Metrics):\n",
            "               avg_sentiment   avg_pnl  total_volume  avg_leverage  pnl_risk\n",
            "avg_sentiment       1.000000  0.087442           NaN           NaN -0.190972\n",
            "avg_pnl             0.087442  1.000000           NaN           NaN  0.941527\n",
            "total_volume             NaN       NaN           NaN           NaN       NaN\n",
            "avg_leverage             NaN       NaN           NaN           NaN       NaN\n",
            "pnl_risk           -0.190972  0.941527           NaN           NaN  1.000000\n",
            "‚úÖ Time-Series plot saved to ds_Khushpreet/outputs/ts_sentiment_vs_pnl.png\n",
            "‚úÖ Bar plot saved to ds_Khushpreet/outputs/bar_metrics_by_sentiment.png\n",
            "\n",
            "--- Key Insights Snapshot ---\n",
            "üí∞ Day with Highest Avg PnL: 2024-10-27 | Avg PnL: 90.50 | Sentiment: Greed\n",
            "üíÄ Day with Lowest Avg PnL: 2023-03-28 | Avg PnL: 0.00 | Sentiment: Greed\n",
            "üöÄ Day with Highest Trading Volume: 2023-03-28 | Total Volume: 0.00 | Sentiment: Greed\n",
            "‚úÖ PDF report generated: ds_Khushpreet/ds_report.pdf\n",
            "‚úÖ Notebook and README generated!\n"
          ]
        }
      ],
      "source": [
        "# ===============================================\n",
        "# üìä BITCOIN SENTIMENT VS TRADER PERFORMANCE\n",
        "# Web3 Trading Team - Data Science Assignment\n",
        "# Assignment Submitter: Khushpreet\n",
        "# ===============================================\n",
        "\n",
        "# --- STEP 1: Mount Google Drive (if needed)\n",
        "from google.colab import drive\n",
        "# Note: Uncomment the line below if you are loading private files from your mounted Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# --- STEP 2: Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os # Added for directory creation\n",
        "import nbformat # Added for notebook generation\n",
        "!pip install reportlab\n",
        "from reportlab.lib.pagesizes import A4 # Added for PDF generation\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer # Added for PDF generation\n",
        "from reportlab.lib.styles import getSampleStyleSheet # Added for PDF generation\n",
        "\n",
        "# --- STEP 3: Create Output Directory Structure (CRITICAL for compliance)\n",
        "ROOT_DIR = 'ds_Khushpreet'\n",
        "OUTPUTS_DIR = os.path.join(ROOT_DIR, 'outputs')\n",
        "CSV_DIR = os.path.join(ROOT_DIR, 'csv_files')\n",
        "\n",
        "# Create the required directories\n",
        "os.makedirs(OUTPUTS_DIR, exist_ok=True)\n",
        "os.makedirs(CSV_DIR, exist_ok=True)\n",
        "print(f\"‚úÖ Created root directory: {ROOT_DIR} and subdirectories.\")\n",
        "\n",
        "# --- STEP 4: Load datasets\n",
        "# Using direct Google Drive 'uc' links for public access\n",
        "try:\n",
        "    # Historical Trader Data from Hyperliquid\n",
        "    trades = pd.read_csv(\"https://drive.google.com/uc?id=1IAfLZwu6rJzyWKgBToqwSmmVYU6VbjVs\")\n",
        "    # Fear & Greed Index\n",
        "    sent = pd.read_csv(\"https://drive.google.com/uc?id=1PgQC0tO8XN-wqkNyghWc_-mnrYv_nhSf\")\n",
        "    print(\"‚úÖ Files loaded successfully!\")\n",
        "    print(\"\\nTrades shape:\", trades.shape)\n",
        "    print(\"Sentiment shape:\", sent.shape)\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading files: {e}\")\n",
        "    # Exit or handle error gracefully if loading fails\n",
        "\n",
        "# --- STEP 5: Preprocess and Clean Data\n",
        "# Convert Timestamps\n",
        "trades['Timestamp'] = pd.to_datetime(trades['Timestamp'], unit='ms', errors='coerce')\n",
        "trades['Date'] = trades['Timestamp'].dt.date\n",
        "\n",
        "# Convert Sentiment Dates\n",
        "sent.rename(columns={'date': 'datetime_str', 'classification': 'classification_mode'}, inplace=True)\n",
        "sent['datetime'] = pd.to_datetime(sent['datetime_str'], errors='coerce')\n",
        "sent['Date'] = sent['datetime'].dt.date\n",
        "\n",
        "# Clean numeric columns (convert to numeric, handle errors by coercing to NaN)\n",
        "trades['Closed PnL'] = pd.to_numeric(trades['Closed PnL'], errors='coerce')\n",
        "trades['leverage'] = pd.to_numeric(trades.get('leverage', pd.Series(0, index=trades.index)), errors='coerce') # Safely access 'leverage' and default to 0\n",
        "trades['size'] = pd.to_numeric(trades.get('size', pd.Series(0, index=trades.index)), errors='coerce') # Safely access 'size' and default to 0\n",
        "trades.dropna(subset=['Date', 'Closed PnL', 'leverage', 'size'], inplace=True) # Drop rows with NaN in key columns\n",
        "sent.dropna(subset=['Date', 'value'], inplace=True)\n",
        "\n",
        "# --- STEP 6: Aggregate Sentiment by day\n",
        "# Calculate Mean Sentiment (value) and Modal Classification (Fear/Greed)\n",
        "sent_daily = sent.groupby('Date', as_index=False).agg(\n",
        "    avg_sentiment=('value', 'mean'),\n",
        "    classification=('classification_mode', lambda x: x.mode()[0] if not x.mode().empty else np.nan)\n",
        ")\n",
        "\n",
        "# --- STEP 7: Aggregate Trader Performance by day (incorporating PnL, Risk, Volume, Leverage)\n",
        "# Risk proxy: Standard Deviation of PnL or Volatility of size\n",
        "# Volume: Sum of trade 'size'\n",
        "perf_daily = trades.groupby('Date', as_index=False).agg(\n",
        "    avg_pnl=('Closed PnL', 'mean'),             # Profitability\n",
        "    total_volume=('size', 'sum'),               # Volume\n",
        "    total_trades=('Closed PnL', 'count'),       # Activity\n",
        "    avg_leverage=('leverage', 'mean'),          # Leverage/Risk\n",
        "    pnl_std=('Closed PnL', 'std'),              # Risk Proxy: PnL Standard Deviation\n",
        ")\n",
        "perf_daily.rename(columns={'pnl_std': 'pnl_risk'}, inplace=True) # Rename for clarity\n",
        "\n",
        "# Save the aggregated data to the required CSV folder\n",
        "perf_daily.to_csv(os.path.join(CSV_DIR, 'daily_performance.csv'), index=False)\n",
        "sent_daily.to_csv(os.path.join(CSV_DIR, 'daily_sentiment.csv'), index=False)\n",
        "print(f\"‚úÖ Aggregated data saved to {CSV_DIR}\")\n",
        "\n",
        "# --- STEP 8: Merge both datasets\n",
        "merged = pd.merge(perf_daily, sent_daily, on='Date', how='inner')\n",
        "print(\"\\nMerged dataset preview:\")\n",
        "print(merged.head())\n",
        "# Save the final merged dataset\n",
        "merged.to_csv(os.path.join(CSV_DIR, 'merged_sentiment_performance.csv'), index=False)\n",
        "\n",
        "# --- STEP 9: Analyze Relationships (Correlation)\n",
        "print(\"\\nüìà Correlation Matrix (Sentiment vs Key Metrics):\")\n",
        "# Including newly calculated metrics: volume, risk, and leverage\n",
        "correlation_matrix = merged[['avg_sentiment', 'avg_pnl', 'total_volume', 'avg_leverage', 'pnl_risk']].corr()\n",
        "print(correlation_matrix)\n",
        "\n",
        "# --- STEP 10: Visualize Trends (Visualization 1: Time Series)\n",
        "plt.figure(figsize=(14, 7))\n",
        "ax1 = sns.lineplot(data=merged, x='Date', y='avg_sentiment', color='orange', label='Avg Sentiment (Fear‚ÄìGreed Index)')\n",
        "ax1.set_ylabel('Avg Sentiment (Fear‚ÄìGreed Index)', color='orange')\n",
        "ax1.tick_params(axis='y', labelcolor='orange')\n",
        "\n",
        "ax2 = plt.twinx(ax1)\n",
        "sns.lineplot(data=merged, x='Date', y='avg_pnl', color='blue', label='Avg PnL', ax=ax2)\n",
        "ax2.set_ylabel('Avg PnL', color='blue')\n",
        "ax2.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "# Manually merge the legends\n",
        "lines, labels = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
        "\n",
        "plt.title('Time-Series: Market Sentiment vs Trader Profitability')\n",
        "plt.xlabel('Date')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUTS_DIR, 'ts_sentiment_vs_pnl.png')) # Save image\n",
        "plt.close() # Close plot to free memory\n",
        "print(f\"‚úÖ Time-Series plot saved to {OUTPUTS_DIR}/ts_sentiment_vs_pnl.png\")\n",
        "\n",
        "# --- STEP 11: Visualize Sentiment Comparison (Visualization 2: Bar Plot)\n",
        "plt.figure(figsize=(10, 5))\n",
        "# Calculate the mean of key metrics based on the daily classification (Fear/Greed)\n",
        "sentiment_comparison = merged.groupby('classification', as_index=False)[['avg_pnl', 'total_volume', 'avg_leverage']].mean()\n",
        "sentiment_comparison_melted = sentiment_comparison.melt(id_vars='classification',\n",
        "                                                     value_vars=['avg_pnl', 'total_volume', 'avg_leverage'],\n",
        "                                                     var_name='Metric', value_name='Average Value')\n",
        "\n",
        "sns.barplot(data=sentiment_comparison_melted, x='Metric', y='Average Value', hue='classification')\n",
        "plt.title('Trader Behavior Metrics by Market Sentiment (Fear vs Greed)')\n",
        "plt.ylabel('Average Value')\n",
        "plt.xlabel('Trader Metric')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUTS_DIR, 'bar_metrics_by_sentiment.png')) # Save image\n",
        "plt.close() # Close plot\n",
        "print(f\"‚úÖ Bar plot saved to {OUTPUTS_DIR}/bar_metrics_by_sentiment.png\")\n",
        "\n",
        "# --- STEP 12: Key Insight Snapshot\n",
        "best_pnl_day = merged.loc[merged['avg_pnl'].idxmax()]\n",
        "worst_pnl_day = merged.loc[merged['avg_pnl'].idxmin()]\n",
        "best_volume_day = merged.loc[merged['total_volume'].idxmax()]\n",
        "\n",
        "print(\"\\n--- Key Insights Snapshot ---\")\n",
        "print(f\"üí∞ Day with Highest Avg PnL: {best_pnl_day['Date']} | Avg PnL: {best_pnl_day['avg_pnl']:.2f} | Sentiment: {best_pnl_day['classification']}\")\n",
        "print(f\"üíÄ Day with Lowest Avg PnL: {worst_pnl_day['Date']} | Avg PnL: {worst_pnl_day['avg_pnl']:.2f} | Sentiment: {worst_pnl_day['classification']}\")\n",
        "print(f\"üöÄ Day with Highest Trading Volume: {best_volume_day['Date']} | Total Volume: {best_volume_day['total_volume']:.2f} | Sentiment: {best_volume_day['classification']}\")\n",
        "\n",
        "# --- STEP 13: PDF & README.md\n",
        "# =============================================\n",
        "# STEP 8: Generate PDF Report\n",
        "# =============================================\n",
        "styles = getSampleStyleSheet()\n",
        "REPORT_PATH = os.path.join(ROOT_DIR, \"ds_report.pdf\")\n",
        "doc = SimpleDocTemplate(REPORT_PATH, pagesize=A4)\n",
        "story = []\n",
        "\n",
        "story.append(Paragraph(\"<b>üìä Bitcoin Market Sentiment & Trader Performance Analysis</b>\", styles[\"Title\"]))\n",
        "story.append(Spacer(1, 12))\n",
        "story.append(Paragraph(\n",
        "    \"This report explores the relationship between trader performance (PnL, volume) \"\n",
        "    \"and market sentiment (Fear/Greed Index) across daily intervals.\", styles[\"BodyText\"]))\n",
        "story.append(Spacer(1, 12))\n",
        "\n",
        "# Check if insights and mw_text are available from previous steps\n",
        "# If not, you might need to recalculate them here or handle their absence\n",
        "# For now, assuming they are available from previous execution\n",
        "if 'insights' in locals() and 'mw_text' in locals():\n",
        "    story.append(Paragraph(\"<b>üîπ Key Insights Snapshot:</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Paragraph(insights.replace(\"\\n\", \"<br/>\"), styles[\"BodyText\"]))\n",
        "    story.append(Spacer(1, 12))\n",
        "    story.append(Paragraph(f\"<b>Statistical Test:</b> {mw_text}\", styles[\"BodyText\"]))\n",
        "    story.append(Spacer(1, 12))\n",
        "    story.append(Paragraph(\n",
        "        \"These insights suggest that trader profitability and market sentiment are correlated, \"\n",
        "        \"with higher PnL often observed during more optimistic (Greed) phases.\", styles[\"BodyText\"]))\n",
        "else:\n",
        "    story.append(Paragraph(\"<b>üîπ Key Insights Snapshot:</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Paragraph(\"Insights could not be generated due to missing data or previous errors.\", styles[\"BodyText\"]))\n",
        "    story.append(Spacer(1, 12))\n",
        "    story.append(Paragraph(\"<b>Statistical Test:</b> Statistical test could not be performed.\", styles[\"BodyText\"]))\n",
        "\n",
        "doc.build(story)\n",
        "print(f\"‚úÖ PDF report generated: {REPORT_PATH}\")\n",
        "\n",
        "# =============================================\n",
        "# üîπ STEP 9: Notebook + README\n",
        "# =============================================\n",
        "NB1 = os.path.join(ROOT_DIR, \"notebook_1.ipynb\")\n",
        "README_PATH = os.path.join(ROOT_DIR, \"README.md\")\n",
        "nb = nbformat.v4.new_notebook()\n",
        "nb['cells'] = [\n",
        "    nbformat.v4.new_markdown_cell(\"# Notebook 1 ‚Äî Sentiment vs Trader Performance\\nSubmitter: Khushpreet\"),\n",
        "    nbformat.v4.new_markdown_cell(\"## Overview\\nThis notebook analyzes the link between Fear/Greed sentiment data and trading performance.\"),\n",
        "    nbformat.v4.new_code_cell(\"import pandas as pd\\nmerged = pd.read_csv('csv_files/merged_sentiment_performance.csv')\\nmerged.head()\"),\n",
        "]\n",
        "with open(NB1, \"w\", encoding=\"utf-8\") as f: nbformat.write(nb, f)\n",
        "\n",
        "readme_text = f\"\"\"\n",
        "# ds_Khushpreet\n",
        "\n",
        "### Contents\n",
        "- `notebook_1.ipynb` ‚Äî quick analysis notebook\n",
        "- `csv_files/merged_sentiment_performance.csv` ‚Äî combined dataset\n",
        "- `outputs/pnl_vs_sentiment.png` ‚Äî visualization\n",
        "- `ds_report.pdf` ‚Äî full PDF report\n",
        "- `README.md` ‚Äî this file\n",
        "\"\"\"\n",
        "with open(README_PATH, \"w\") as f: f.write(readme_text)\n",
        "\n",
        "print(\"‚úÖ Notebook and README generated!\")\n",
        "#\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSgILXyxdA3e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}